#!/usr/bin/env python3
"""
åŸºäºSARIFæ¼æ´ä¿¡æ¯çš„è‡ªåŠ¨ä¿®å¤å¼•æ“
ä½¿ç”¨Minimax AIç”Ÿæˆä¿®å¤ä»£ç å¹¶è‡ªåŠ¨åº”ç”¨
"""

import json
import logging
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

from .minimax_client import MinimaxClient, AIResponse
from .sarif_parser import SarifParser, Vulnerability, SeverityLevel

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class FixResult:
    """ä¿®å¤ç»“æœ"""
    vulnerability: Vulnerability
    original_content: str
    fixed_content: str
    explanation: str
    ai_suggestion: str
    applied: bool = False
    error: Optional[str] = None


class AutoFixEngine:
    """è‡ªåŠ¨ä¿®å¤å¼•æ“"""

    def __init__(self, minimax_client: MinimaxClient):
        """
        åˆå§‹åŒ–è‡ªåŠ¨ä¿®å¤å¼•æ“

        Args:
            minimax_client: Minimax AIå®¢æˆ·ç«¯
        """
        self.minimax_client = minimax_client
        self.sarif_parser = SarifParser()
        self.fix_results: List[FixResult] = []

    def process_vulnerabilities(self, vulnerabilities: List[Vulnerability], workflows_directory: Path) -> List[FixResult]:
        """
        å¤„ç†æ¼æ´åˆ—è¡¨ï¼Œç”Ÿæˆä¿®å¤æ–¹æ¡ˆï¼ˆå•ä¸ªå¤„ç†æ¨¡å¼ï¼‰

        Args:
            vulnerabilities: æ¼æ´åˆ—è¡¨
            workflows_directory: GitHub workflowsç›®å½•

        Returns:
            ä¿®å¤ç»“æœåˆ—è¡¨
        """
        logger.info(f"å¼€å§‹å¤„ç† {len(vulnerabilities)} ä¸ªæ¼æ´")

        # ä¸ºæ¯ä¸ªæ¼æ´ç”Ÿæˆä¿®å¤æ–¹æ¡ˆï¼ˆå•ä¸ªå¤„ç†æ¨¡å¼ï¼‰
        for vulnerability in vulnerabilities:
            try:
                # é‡ç½®æ€ç»´é“¾è®°å½•å™¨ï¼Œç¡®ä¿æ¯ä¸ªæ¼æ´ç‹¬ç«‹å¤„ç†
                self.minimax_client.reset_chain_of_thought()
                fix_result = self._generate_fix_for_vulnerability(vulnerability, workflows_directory)
                if fix_result:
                    self.fix_results.append(fix_result)
            except Exception as e:
                logger.error(f"ç”Ÿæˆä¿®å¤æ–¹æ¡ˆå¤±è´¥ {vulnerability.rule_id}: {str(e)}")
                # å³ä½¿å¤±è´¥ä¹Ÿè¦é‡ç½®ï¼Œé¿å…å½±å“ä¸‹ä¸€ä¸ªæ¼æ´
                self.minimax_client.reset_chain_of_thought()

        logger.info(f"ç”Ÿæˆäº† {len(self.fix_results)} ä¸ªä¿®å¤æ–¹æ¡ˆ")
        return self.fix_results

    def process_sarif_files(self, sarif_directory: Path, workflows_directory: Path) -> List[FixResult]:
        """
        å¤„ç†SARIFæ–‡ä»¶ç›®å½•ï¼Œç”Ÿæˆä¿®å¤æ–¹æ¡ˆ

        Args:
            sarif_directory: SARIFæ–‡ä»¶ç›®å½•
            workflows_directory: GitHub workflowsç›®å½•

        Returns:
            ä¿®å¤ç»“æœåˆ—è¡¨
        """
        logger.info(f"å¼€å§‹å¤„ç†SARIFæ–‡ä»¶: {sarif_directory}")

        # è§£ææ‰€æœ‰SARIFæ–‡ä»¶
        vulnerabilities = self.sarif_parser.parse_directory(sarif_directory)
        logger.info(f"æå–åˆ° {len(vulnerabilities)} ä¸ªæ¼æ´")

        # ä½¿ç”¨é€šç”¨çš„æ¼æ´å¤„ç†æ–¹æ³•
        return self.process_vulnerabilities(vulnerabilities, workflows_directory)

    def _generate_fix_for_vulnerability(self, vulnerability: Vulnerability, workflows_directory: Path) -> Optional[FixResult]:
        """
        ä¸ºå•ä¸ªæ¼æ´ç”Ÿæˆä¿®å¤æ–¹æ¡ˆ

        Args:
            vulnerability: æ¼æ´ä¿¡æ¯
            workflows_directory: workflowsç›®å½•

        Returns:
            ä¿®å¤ç»“æœ
        """
        logger.info(f"ä¸ºæ¼æ´ {vulnerability.rule_id} ç”Ÿæˆä¿®å¤æ–¹æ¡ˆ")

        # è·å–å¯¹åº”çš„workflowæ–‡ä»¶
        workflow_file = self._find_workflow_file(vulnerability, workflows_directory)
        if not workflow_file or not workflow_file.exists():
            logger.warning(f"æœªæ‰¾åˆ°å¯¹åº”çš„workflowæ–‡ä»¶: {vulnerability.location.workflow_name}")
            return None

        # è¯»å–workflowå†…å®¹
        try:
            with open(workflow_file, 'r', encoding='utf-8') as f:
                original_content = f.read()
        except Exception as e:
            logger.error(f"è¯»å–workflowæ–‡ä»¶å¤±è´¥ {workflow_file}: {str(e)}")
            return None

        # è°ƒç”¨AIç”Ÿæˆä¿®å¤å»ºè®®
        vulnerability_dict = {
            "rule_id": vulnerability.rule_id,
            "message": vulnerability.message,
            "severity": vulnerability.severity.value,
            "workflow": vulnerability.location.workflow_name,
            "job": vulnerability.location.job_name,
            "step": vulnerability.location.step_name,
            "workflow_file": str(workflow_file)
        }

        try:
            # åˆ†ææ¼æ´
            analysis_response = self.minimax_client.analyze_vulnerability(vulnerability_dict)

            # ç”Ÿæˆä¿®å¤ä»£ç 
            fix_response = self.minimax_client.generate_fix_code(original_content, vulnerability_dict)

            # å°è¯•åº”ç”¨ä¿®å¤
            fixed_content, explanation = self._apply_fix(original_content, vulnerability, fix_response.content)

            return FixResult(
                vulnerability=vulnerability,
                original_content=original_content,
                fixed_content=fixed_content,
                explanation=explanation,
                ai_suggestion=fix_response.content,
                applied=(fixed_content != original_content)
            )

        except Exception as e:
            logger.error(f"AIä¿®å¤ç”Ÿæˆå¤±è´¥: {str(e)}")
            return FixResult(
                vulnerability=vulnerability,
                original_content=original_content,
                fixed_content=original_content,
                explanation="ä¿®å¤å¤±è´¥",
                ai_suggestion="",
                applied=False,
                error=str(e)
            )

    def _find_workflow_file(self, vulnerability: Vulnerability, workflows_directory: Path) -> Optional[Path]:
        """
        æ ¹æ®æ¼æ´ä¿¡æ¯æ‰¾åˆ°å¯¹åº”çš„workflowæ–‡ä»¶

        Args:
            vulnerability: æ¼æ´ä¿¡æ¯
            workflows_directory: workflowsç›®å½•

        Returns:
            workflowæ–‡ä»¶è·¯å¾„
        """
        # ä»SARIFæ–‡ä»¶åä¸­æå–ç¼–å·ï¼Œæ‰¾åˆ°å¯¹åº”çš„workflowæ–‡ä»¶
        workflow_number = self._extract_workflow_number(vulnerability.workflow_file)

        # å°è¯•å¤šç§å¯èƒ½çš„æ–‡ä»¶åæ ¼å¼
        possible_names = [
            f"{workflow_number}.yml",
            f"{workflow_number}.yaml",
            f"workflow_{workflow_number}.yml",
            f"workflow_{workflow_number}.yaml"
        ]

        for name in possible_names:
            workflow_file = workflows_directory / name
            if workflow_file.exists():
                return workflow_file

        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ—å‡ºæ‰€æœ‰æ–‡ä»¶å°è¯•åŒ¹é…
        workflow_files = list(workflows_directory.glob("*.yml")) + list(workflows_directory.glob("*.yaml"))

        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
        if workflow_files:
            workflow_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            # è¿”å›ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼ˆæœ€æ–°ä¿®æ”¹çš„ï¼‰
            return workflow_files[0]

        return None

    def _extract_workflow_number(self, sarif_file_name: str) -> str:
        """ä»SARIFæ–‡ä»¶åæå–å·¥ä½œæµç¼–å·"""
        # æ ¼å¼: "argusSecurityBot#vwbench#1.sarif"
        parts = sarif_file_name.split("#")
        if len(parts) >= 3:
            return parts[2].replace(".sarif", "")
        return "1"  # é»˜è®¤è¿”å›1

    def _apply_fix(self, original_content: str, vulnerability: Vulnerability, ai_suggestion: str) -> Tuple[str, str]:
        """
        åº”ç”¨AIç”Ÿæˆçš„ä¿®å¤

        Args:
            original_content: åŸå§‹å†…å®¹
            vulnerability: æ¼æ´ä¿¡æ¯
            ai_suggestion: AIä¿®å¤å»ºè®®

        Returns:
            (ä¿®å¤åçš„å†…å®¹, è§£é‡Š)
        """
        logger.info(f"åº”ç”¨ä¿®å¤: {vulnerability.rule_id}")

        # å°è¯•ä»AIå»ºè®®ä¸­æå–YAMLä»£ç 
        fixed_content = self._extract_yaml_from_suggestion(ai_suggestion)

        if fixed_content and self._validate_yaml(fixed_content):
            explanation = f"å·²æ ¹æ®AIå»ºè®®ä¿®å¤ {vulnerability.rule_id} æ¼æ´"
            return fixed_content, explanation

        # å¦‚æœAIå»ºè®®æ— æ•ˆï¼Œå°è¯•åŸºäºè§„åˆ™çš„ä¿®å¤
        fixed_content = self._apply_rule_based_fix(original_content, vulnerability)

        if fixed_content != original_content:
            explanation = f"å·²åº”ç”¨è§„åˆ™ä¿®å¤ {vulnerability.rule_id} æ¼æ´"
            return fixed_content, explanation

        # æ— æ³•ä¿®å¤ï¼Œè¿”å›åŸå†…å®¹
        explanation = f"æ— æ³•è‡ªåŠ¨ä¿®å¤ {vulnerability.rule_id}ï¼Œéœ€è¦æ‰‹åŠ¨å¤„ç†"
        return original_content, explanation

    def _extract_yaml_from_suggestion(self, suggestion: str) -> Optional[str]:
        """ä»AIå»ºè®®ä¸­æå–YAMLä»£ç """
        # æŸ¥æ‰¾YAMLä»£ç å—
        yaml_pattern = r'```(?:yaml|yml)?\n(.*?)\n```'
        matches = re.findall(yaml_pattern, suggestion, re.DOTALL)

        if matches:
            yaml_content = matches[0].strip()
            if self._validate_yaml(yaml_content):
                return yaml_content

        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œæ£€æŸ¥æ•´ä¸ªå»ºè®®æ˜¯å¦ä¸ºYAML
        if self._validate_yaml(suggestion):
            return suggestion

        return None

    def _validate_yaml(self, content: str) -> bool:
        """éªŒè¯YAMLå†…å®¹æ˜¯å¦æœ‰æ•ˆ"""
        try:
            import yaml
            yaml.safe_load(content)
            return True
        except:
            return False

    def _apply_rule_based_fix(self, content: str, vulnerability: Vulnerability) -> str:
        """åº”ç”¨åŸºäºè§„åˆ™çš„ä¿®å¤"""
        if vulnerability.rule_id == "ContextToSink":
            return self._fix_context_to_sink(content, vulnerability)
        else:
            # å…¶ä»–è§„åˆ™çš„ä¿®å¤é€»è¾‘
            return content

    def _fix_context_to_sink(self, content: str, vulnerability: Vulnerability) -> str:
        """ä¿®å¤Context-to-Sinkæ¼æ´"""
        # åŸºäºæ¼æ´æ¶ˆæ¯ç¡®å®šä¿®å¤ç­–ç•¥
        message = vulnerability.message.lower()

        if "issue.title" in message:
            # ä¸ºissue.titleæ·»åŠ éªŒè¯
            content = self._add_input_validation(content, "github.event.issue.title")
        elif "commits" in message:
            # ä¸ºcommitsæ·»åŠ éªŒè¯
            content = self._add_input_validation(content, "github.event.commits")
        elif "comment.body" in message:
            # ä¸ºcomment.bodyæ·»åŠ éªŒè¯
            content = self._add_input_validation(content, "github.event.comment.body")

        return content

    def _add_input_validation(self, content: str, context_path: str) -> str:
        """ä¸ºè¾“å…¥æ·»åŠ éªŒè¯é€»è¾‘"""
        # åœ¨runå‘½ä»¤å‰åæ·»åŠ éªŒè¯æ­¥éª¤
        validation_snippet = f"""
      - name: Validate input
        run: |
          # éªŒè¯ {context_path}
          if [[ "${{{{ {context_path} }}}}" =~ ^[a-zA-Z0-9_\\-\\s]+$ ]]; then
            echo "Input validation passed"
          else
            echo "Invalid input detected"
            exit 1
          fi
"""

        # åœ¨ç¬¬ä¸€ä¸ªrunæ­¥éª¤å‰æ’å…¥éªŒè¯æ­¥éª¤
        if "    run: |" in content:
            content = content.replace("    run: |", validation_snippet + "    run: |", 1)

        return content

    def apply_all_fixes(self, workflows_directory: Path, backup_directory: Optional[Path] = None) -> Dict[str, Any]:
        """
        åº”ç”¨æ‰€æœ‰ä¿®å¤åˆ°æ–‡ä»¶

        Args:
            workflows_directory: workflowsç›®å½•
            backup_directory: å¤‡ä»½ç›®å½•ï¼ˆå¯é€‰ï¼‰

        Returns:
            ä¿®å¤ç»Ÿè®¡ä¿¡æ¯
        """
        logger.info("å¼€å§‹åº”ç”¨æ‰€æœ‰ä¿®å¤")

        if backup_directory:
            backup_directory.mkdir(parents=True, exist_ok=True)

        applied_count = 0
        failed_count = 0
        results_by_file = {}

        for fix_result in self.fix_results:
            if not fix_result.applied:
                continue

            try:
                workflow_file = self._find_workflow_file(fix_result.vulnerability, workflows_directory)
                if not workflow_file:
                    failed_count += 1
                    continue

                # åˆ›å»ºå¤‡ä»½
                if backup_directory:
                    backup_file = backup_directory / workflow_file.name
                    backup_file.write_text(fix_result.original_content, encoding='utf-8')

                # åº”ç”¨ä¿®å¤
                workflow_file.write_text(fix_result.fixed_content, encoding='utf-8')
                applied_count += 1

                # è®°å½•ç»“æœ
                if workflow_file.name not in results_by_file:
                    results_by_file[workflow_file.name] = []
                results_by_file[workflow_file.name].append({
                    "vulnerability": fix_result.vulnerability.rule_id,
                    "explanation": fix_result.explanation,
                    "applied": True
                })

                logger.info(f"å·²ä¿®å¤: {workflow_file.name} - {fix_result.vulnerability.rule_id}")

            except Exception as e:
                logger.error(f"åº”ç”¨ä¿®å¤å¤±è´¥: {str(e)}")
                failed_count += 1

        results = {
            "total_fixes": len(self.fix_results),
            "applied": applied_count,
            "failed": failed_count,
            "results_by_file": results_by_file
        }

        logger.info(f"ä¿®å¤å®Œæˆ: {applied_count} æˆåŠŸ, {failed_count} å¤±è´¥")
        return results

    def export_fix_report(self, output_path: Path) -> None:
        """å¯¼å‡ºä¿®å¤æŠ¥å‘Šï¼ˆJSONæ ¼å¼ï¼‰"""
        report = {
            "total_vulnerabilities": len(self.fix_results),
            "fixes": [
                {
                    "rule_id": fix.vulnerability.rule_id,
                    "severity": fix.vulnerability.severity.value,
                    "message": fix.vulnerability.message,
                    "workflow": fix.vulnerability.location.workflow_name,
                    "job": fix.vulnerability.location.job_name,
                    "step": fix.vulnerability.location.step_name,
                    "applied": fix.applied,
                    "explanation": fix.explanation,
                    "ai_suggestion": fix.ai_suggestion[:500] + "..." if len(fix.ai_suggestion) > 500 else fix.ai_suggestion,
                    "error": fix.error
                }
                for fix in self.fix_results
            ]
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logger.info(f"ä¿®å¤æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_path}")

    def export_fix_report_markdown(self, output_path: Path) -> None:
        """å¯¼å‡ºä¿®å¤æŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰"""
        from datetime import datetime
        
        total = len(self.fix_results)
        applied = sum(1 for fix in self.fix_results if fix.applied)
        failed = total - applied
        
        md_content = [
            "# ğŸ”§ SARIFè‡ªåŠ¨ä¿®å¤æŠ¥å‘Š\n",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
            f"**æ€»æ¼æ´æ•°**: {total}\n",
            f"**æˆåŠŸä¿®å¤**: {applied}\n",
            f"**ä¿®å¤å¤±è´¥**: {failed}\n",
            f"**ä¿®å¤ç‡**: {(applied/total*100):.1f}%\n",
            "\n---\n\n",
            "## ğŸ“‹ è¯¦ç»†ä¿®å¤ç»“æœ\n\n"
        ]
        
        for i, fix in enumerate(self.fix_results, 1):
            status = "âœ…" if fix.applied else "âŒ"
            md_content.append(f"### {i}. {status} {fix.vulnerability.rule_id}\n\n")
            md_content.append(f"- **ä¸¥é‡æ€§**: {fix.vulnerability.severity.value}\n")
            md_content.append(f"- **æ¼æ´æè¿°**: {fix.vulnerability.message[:200]}{'...' if len(fix.vulnerability.message) > 200 else ''}\n")
            md_content.append(f"- **å·¥ä½œæµ**: {fix.vulnerability.location.workflow_name}\n")
            md_content.append(f"- **ä½œä¸š**: {fix.vulnerability.location.job_name}\n")
            md_content.append(f"- **æ­¥éª¤**: {fix.vulnerability.location.step_name}\n")
            md_content.append(f"- **ä¿®å¤çŠ¶æ€**: {'å·²ä¿®å¤' if fix.applied else 'ä¿®å¤å¤±è´¥'}\n")
            md_content.append(f"- **è¯´æ˜**: {fix.explanation}\n")
            
            if fix.ai_suggestion:
                md_content.append(f"\n**AIä¿®å¤å»ºè®®**:\n\n")
                md_content.append("```yaml\n")
                yaml_match = re.search(r'```(?:yaml|yml)?\n(.*?)\n```', fix.ai_suggestion, re.DOTALL)
                if yaml_match:
                    md_content.append(yaml_match.group(1))
                else:
                    md_content.append(fix.ai_suggestion[:1000])
                md_content.append("\n```\n\n")
            
            if fix.error:
                md_content.append(f"**é”™è¯¯ä¿¡æ¯**: {fix.error}\n")
            
            md_content.append("\n---\n\n")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(''.join(md_content))
        
        logger.info(f"ä¿®å¤æŠ¥å‘Š(Markdown)å·²å¯¼å‡ºåˆ°: {output_path}")

    def print_summary(self) -> None:
        """æ‰“å°ä¿®å¤æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ”§ è‡ªåŠ¨ä¿®å¤å¼•æ“ - ä¿®å¤æ‘˜è¦")
        print("="*60)

        total = len(self.fix_results)
        applied = sum(1 for fix in self.fix_results if fix.applied)
        failed = total - applied

        print(f"ğŸ“Š æ€»æ¼æ´æ•°: {total}")
        print(f"âœ… æˆåŠŸä¿®å¤: {applied}")
        print(f"âŒ ä¿®å¤å¤±è´¥: {failed}")
        print(f"ğŸ“ˆ ä¿®å¤ç‡: {(applied/total*100):.1f}%" if total > 0 else "ğŸ“ˆ ä¿®å¤ç‡: 0%")

        if self.fix_results:
            print("\nğŸ“‹ è¯¦ç»†ä¿®å¤ç»“æœ:")
            for i, fix in enumerate(self.fix_results, 1):
                status = "âœ…" if fix.applied else "âŒ"
                print(f"\n{i}. {status} {fix.vulnerability.rule_id}")
                print(f"   ä¸¥é‡æ€§: {fix.vulnerability.severity.value}")
                print(f"   æè¿°: {fix.vulnerability.message[:100]}...")
                print(f"   è§£é‡Š: {fix.explanation}")

        print("\n" + "="*60)
