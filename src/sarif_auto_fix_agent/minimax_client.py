#!/usr/bin/env python3

import json
import logging
import sys
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class AIModel(Enum):
    MINIMAX_M2 = "MiniMax-M2"
    DEEPSEEK_CHAT = "deepseek-chat"
    DEEPSEEK_CODING = "deepseek-coder"
    ABAB6_CHAT = "abab6.5-chat"
    ABAB6_GPT = "abab6.5-gpt"


@dataclass
class AIRequest:
    model: AIModel
    messages: List[Dict[str, str]]
    temperature: float = 0.7
    max_tokens: int = 4000
    stream: bool = False


@dataclass
class AIResponse:
    content: str
    model: str
    usage: Dict[str, int]
    finish_reason: str
    chain_of_thought: Optional[str] = None


class ChainOfThoughtLogger:
    def __init__(self):
        self.thought_chain: List[Dict[str, Any]] = []
        self.current_step = 0

    def add_step(self, step_name: str, input_data: Any, output_data: Any,
                reasoning: str, confidence: float = 1.0, verbose: bool = False) -> None:
        step = {
            "step": self.current_step,
            "timestamp": time.time(),
            "step_name": step_name,
            "input": input_data,
            "output": output_data,
            "reasoning": reasoning,
            "confidence": confidence
        }
        self.thought_chain.append(step)
        self.current_step += 1

    def _make_serializable(self, obj: Any) -> Any:
        if isinstance(obj, AIResponse):
            return {
                "content": obj.content,
                "model": obj.model,
                "usage": obj.usage,
                "finish_reason": obj.finish_reason,
                "chain_of_thought": obj.chain_of_thought
            }
        elif isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [self._make_serializable(item) for item in obj]
        elif hasattr(obj, '__dict__'):
            return str(obj)
        else:
            return obj

    def export_to_dict(self) -> Dict[str, Any]:
        serializable_steps = [self._make_serializable(step) for step in self.thought_chain]

        return {
            "total_steps": len(self.thought_chain),
            "steps": serializable_steps
        }

    def export_to_json(self, file_path: str) -> None:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(self.export_to_dict(), f, indent=2, ensure_ascii=False)

        logger.info(f"æ€ç»´é“¾å·²å¯¼å‡ºåˆ°: {file_path}")


class MinimaxClient:
    def __init__(self, api_key: str, base_url: str = "https://api.minimaxi.com/v1/text/chatcompletion_v2",
                 model: AIModel = AIModel.MINIMAX_M2):
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.chain_logger = ChainOfThoughtLogger()

        self.session = requests.Session()
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        logger.info(f"Minimaxå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡åž‹: {model.value}")

    def chat(self, messages: List[Dict[str, str]], temperature: float = 0.7,
             max_tokens: int = 4000) -> AIResponse:
        user_msg = next((msg.get("content", "") for msg in messages if msg.get("role") == "user"), "")
        if user_msg:
            logger.info(f"ðŸ’¬ å‘é€è¯·æ±‚ ({self.model.value})...")

        self.chain_logger.add_step(
            "APIè¯·æ±‚å‡†å¤‡",
            {"messages": messages, "messages_count": len(messages), "temperature": temperature, "max_tokens": max_tokens},
            {"model": self.model.value},
            "å‡†å¤‡å‘é€è¯·æ±‚åˆ°Minimax API",
            confidence=1.0,
            verbose=False
        )

        request_data = {
            "model": self.model.value,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": True
        }

        try:
            self.chain_logger.add_step(
                "å‘é€APIè¯·æ±‚",
                {"url": self.base_url},
                "è¯·æ±‚ä¸­...",
                "å‘Minimax APIå‘é€HTTPè¯·æ±‚",
                confidence=1.0,
                verbose=False
            )

            response = self.session.post(
                self.base_url,
                headers=self.headers,
                json=request_data,
                timeout=60,
                stream=True
            )

            response.raise_for_status()

            content = ""
            usage = {}
            finish_reason = "stop"
            model_name = self.model.value

            logger.info("ðŸ¤– AIå“åº”:")
            print("â”€" * 80)
            sys.stdout.flush()

            for line in response.iter_lines():
                if not line:
                    continue

                line_text = line.decode('utf-8')
                if line_text.startswith('data: '):
                    data_str = line_text[6:].strip()
                    if data_str == '[DONE]':
                        break

                    try:
                        data = json.loads(data_str)
                        if "choices" in data and len(data["choices"]) > 0:
                            choice = data["choices"][0]
                            delta = choice.get("delta", {})
                            if "content" in delta:
                                chunk = delta["content"]
                                content += chunk
                                sys.stdout.write(chunk)
                                sys.stdout.flush()

                            if "usage" in data:
                                usage.update(data["usage"])
                            if "finish_reason" in choice and choice["finish_reason"]:
                                finish_reason = choice["finish_reason"]
                            if "model" in data:
                                model_name = data["model"]
                    except json.JSONDecodeError as e:
                        continue

            print()
            print("â”€" * 80)
            sys.stdout.flush()

            self.chain_logger.add_step(
                "å¤„ç†APIå“åº”",
                {"status_code": response.status_code},
                {"content_length": len(content)},
                "è§£æžAPIæµå¼å“åº”æ•°æ®",
                confidence=1.0,
                verbose=False
            )

            ai_response = AIResponse(
                content=content,
                model=model_name,
                usage=usage,
                finish_reason=finish_reason,
                chain_of_thought=self._extract_chain_of_thought(content)
            )

            self.chain_logger.add_step(
                "ç”Ÿæˆæœ€ç»ˆå“åº”",
                {},
                ai_response,
                "æž„å»ºAIå“åº”å¯¹è±¡å¹¶æå–æ€ç»´é“¾",
                confidence=0.9,
                verbose=False
            )

            return ai_response

        except requests.exceptions.RequestException as e:
            error_msg = f"APIè¯·æ±‚å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            self.chain_logger.add_step(
                "APIè¯·æ±‚é”™è¯¯",
                {"error": str(e)},
                None,
                "å¤„ç†APIè¯·æ±‚å¼‚å¸¸",
                confidence=0.0
            )
            raise
        except Exception as e:
            error_msg = f"å“åº”å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            self.chain_logger.add_step(
                "å“åº”å¤„ç†é”™è¯¯",
                {"error": str(e)},
                None,
                "å¤„ç†å“åº”æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸",
                confidence=0.0
            )
            raise

    def _extract_chain_of_thought(self, content: str) -> Optional[str]:
        lines = content.split('\n')
        chain_parts = []

        in_thought_chain = False
        for line in lines:
            line = line.strip()
            if "æ€ç»´é“¾" in line or "æŽ¨ç†è¿‡ç¨‹" in line or "chain of thought" in line.lower():
                in_thought_chain = True
                continue
            elif line.startswith("---") or "ç»“è®º" in line:
                if in_thought_chain:
                    break

            if in_thought_chain and line:
                chain_parts.append(line)

        return '\n'.join(chain_parts) if chain_parts else None

    def analyze_vulnerability(self, vulnerability_data: Dict[str, Any]) -> AIResponse:
        self.chain_logger.add_step(
            "æ¼æ´žåˆ†æžå¼€å§‹",
            vulnerability_data,
            "åˆ†æžä¸­...",
            "å¼€å§‹ä½¿ç”¨AIåˆ†æžæ¼æ´žè¯¦æƒ…",
            confidence=1.0,
            verbose=False
        )

        prompt = self._build_vulnerability_analysis_prompt(vulnerability_data)

        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯GitHub Actionå®‰å…¨ä¸“å®¶ï¼Œä¸“æ³¨åˆ†æžå’Œä¿®å¤å·¥ä½œæµå®‰å…¨æ¼æ´žã€‚è¾“å‡ºç®€æ´ã€ä¸“ä¸šã€å¯æ‰§è¡Œã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        response = self.chat(messages, temperature=0.3, max_tokens=2000)

        self.chain_logger.add_step(
            "æ¼æ´žåˆ†æžå®Œæˆ",
            vulnerability_data,
            response.content,
            f"å®Œæˆæ¼æ´žåˆ†æžï¼Œç”Ÿæˆäº†{len(response.content)}å­—ç¬¦çš„ä¿®å¤å»ºè®®",
            confidence=0.9,
            verbose=False
        )

        return response

    def generate_fix_code(self, workflow_content: str, vulnerability_info: Dict[str, Any]) -> AIResponse:
        self.chain_logger.add_step(
            "ä¿®å¤ä»£ç ç”Ÿæˆå¼€å§‹",
            {"workflow_length": len(workflow_content), "vulnerability": vulnerability_info},
            "ç”Ÿæˆä¸­...",
            "å¼€å§‹ä½¿ç”¨AIç”Ÿæˆå…·ä½“çš„ä¿®å¤ä»£ç ",
            confidence=1.0,
            verbose=False
        )

        prompt = self._build_fix_code_prompt(workflow_content, vulnerability_info)

        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯GitHub Actionå®‰å…¨ä¿®å¤ä¸“å®¶ã€‚è¾“å‡ºå®Œæ•´ã€å®‰å…¨ã€å¯ç”¨çš„YAMLä»£ç ï¼Œä»…ä¿®å¤æŒ‡å®šæ¼æ´žï¼Œä¿æŒåŽŸæœ‰åŠŸèƒ½ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        response = self.chat(messages, temperature=0.2, max_tokens=3000)

        self.chain_logger.add_step(
            "ä¿®å¤ä»£ç ç”Ÿæˆå®Œæˆ",
            {"workflow_length": len(workflow_content)},
            response.content,
            f"ç”Ÿæˆäº†{len(response.content)}å­—ç¬¦çš„ä¿®å¤ä»£ç ",
            confidence=0.9,
            verbose=False
        )

        return response

    def _build_vulnerability_analysis_prompt(self, vulnerability_data: Dict[str, Any]) -> str:
        return f"""åˆ†æžGitHub Actionå®‰å…¨æ¼æ´žå¹¶æä¾›ä¿®å¤æ–¹æ¡ˆã€‚

æ¼æ´žä¿¡æ¯ï¼š
- è§„åˆ™ID: {vulnerability_data.get('rule_id', 'unknown')}
- ä¸¥é‡æ€§: {vulnerability_data.get('severity', 'unknown')}
- æè¿°: {vulnerability_data.get('message', 'unknown')}
- ä½ç½®: {vulnerability_data.get('workflow', 'unknown')}/{vulnerability_data.get('job', 'unknown')}/{vulnerability_data.get('step', 'unknown')}

è¾“å‡ºè¦æ±‚ï¼š
1. ç®€è¦è¯´æ˜Žå®‰å…¨é£Žé™©å’Œæ”»å‡»å‘é‡
2. æä¾›å¯è¡Œçš„ä¿®å¤æ–¹æ¡ˆ
3. è¯„ä¼°ä¿®å¤ä¼˜å…ˆçº§ï¼ˆP0/P1/P2ï¼‰
4. è¯´æ˜Žä¿®å¤ç†ç”±

è¯·ç”¨ç®€æ´ã€ç»“æž„åŒ–çš„æ–¹å¼è¾“å‡ºã€‚"""

    def _build_fix_code_prompt(self, workflow_content: str, vulnerability_info: Dict[str, Any]) -> str:
        return f"""ä¿®å¤ä»¥ä¸‹GitHub Actionå·¥ä½œæµçš„å®‰å…¨æ¼æ´žï¼š

å½“å‰å·¥ä½œæµï¼š
```yaml
{workflow_content}
```

æ¼æ´žä¿¡æ¯ï¼š
- ç±»åž‹: {vulnerability_info.get('rule_id', 'unknown')}
- æè¿°: {vulnerability_info.get('message', 'unknown')}
- ä½ç½®: {vulnerability_info.get('workflow', 'unknown')}/{vulnerability_info.get('job', 'unknown')}/{vulnerability_info.get('step', 'unknown')}

è¦æ±‚ï¼š
1. ä»…ä¿®å¤æŒ‡å®šæ¼æ´žï¼Œä¸æ”¹åŠ¨å…¶ä»–ä»£ç 
2. ä¿æŒåŽŸæœ‰åŠŸèƒ½ä¸å˜
3. ä½¿ç”¨å®‰å…¨çš„ç¼–ç å®žè·µï¼ˆè¾“å…¥éªŒè¯ã€å‚æ•°åŒ–æŸ¥è¯¢ç­‰ï¼‰
4. è¾“å‡ºå®Œæ•´ä¿®å¤åŽçš„YAMLä»£ç 
5. ç”¨æ³¨é‡Šè¯´æ˜Žä¿®å¤ç†ç”±

ç›´æŽ¥è¾“å‡ºä¿®å¤åŽçš„YAMLä»£ç ï¼ˆåŒ…å«```yamlä»£ç å—ï¼‰ã€‚"""

    def get_chain_of_thought(self) -> ChainOfThoughtLogger:
        return self.chain_logger

    def reset_chain_of_thought(self) -> None:
        self.chain_logger = ChainOfThoughtLogger()
