#!/usr/bin/env python3
"""
Minimax AI APIé›†æˆæ¨¡å—
æä¾›ä¸Minimax APIçš„è‡ªå®šä¹‰æ¥å…¥ï¼Œç”¨äºç”Ÿæˆæ™ºèƒ½ä¿®å¤å»ºè®®å’Œæ€ç»´é“¾æ¨ç†
"""

import json
import logging
import sys
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class AIModel(Enum):
    """å¯ç”¨çš„AIæ¨¡å‹"""
    MINIMAX_M2 = "MiniMax-M2"
    DEEPSEEK_CHAT = "deepseek-chat"
    DEEPSEEK_CODING = "deepseek-coder"
    ABAB6_CHAT = "abab6.5-chat"
    ABAB6_GPT = "abab6.5-gpt"


@dataclass
class AIRequest:
    """AIè¯·æ±‚é…ç½®"""
    model: AIModel
    messages: List[Dict[str, str]]
    temperature: float = 0.7
    max_tokens: int = 4000
    stream: bool = False


@dataclass
class AIResponse:
    """AIå“åº”ç»“æœ"""
    content: str
    model: str
    usage: Dict[str, int]
    finish_reason: str
    chain_of_thought: Optional[str] = None


class ChainOfThoughtLogger:
    """æ€ç»´é“¾è®°å½•å™¨"""

    def __init__(self):
        self.thought_chain: List[Dict[str, Any]] = []
        self.current_step = 0

    def add_step(self, step_name: str, input_data: Any, output_data: Any,
                reasoning: str, confidence: float = 1.0, verbose: bool = False) -> None:
        """æ·»åŠ æ€ç»´é“¾æ­¥éª¤ï¼ˆé™é»˜æ¨¡å¼ï¼Œä¸è¾“å‡ºæ—¥å¿—ï¼‰"""
        step = {
            "step": self.current_step,
            "timestamp": time.time(),
            "step_name": step_name,
            "input": input_data,
            "output": output_data,
            "reasoning": reasoning,
            "confidence": confidence
        }
        self.thought_chain.append(step)
        self.current_step += 1

    def _make_serializable(self, obj: Any) -> Any:
        """é€’å½’åœ°å°†å¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼"""
        if isinstance(obj, AIResponse):
            # å°†AIResponseå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
            return {
                "content": obj.content,
                "model": obj.model,
                "usage": obj.usage,
                "finish_reason": obj.finish_reason,
                "chain_of_thought": obj.chain_of_thought
            }
        elif isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [self._make_serializable(item) for item in obj]
        elif hasattr(obj, '__dict__'):
            # å¤„ç†å…¶ä»–è‡ªå®šä¹‰å¯¹è±¡
            return str(obj)
        else:
            return obj

    def export_to_dict(self) -> Dict[str, Any]:
        """å¯¼å‡ºæ€ç»´é“¾ä¸ºå­—å…¸"""
        # è½¬æ¢æ­¥éª¤æ•°æ®ï¼Œç¡®ä¿æ‰€æœ‰å¯¹è±¡éƒ½å¯åºåˆ—åŒ–
        serializable_steps = [self._make_serializable(step) for step in self.thought_chain]
        
        return {
            "total_steps": len(self.thought_chain),
            "steps": serializable_steps
        }

    def export_to_json(self, file_path: str) -> None:
        """å¯¼å‡ºæ€ç»´é“¾åˆ°JSONæ–‡ä»¶"""
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(self.export_to_dict(), f, indent=2, ensure_ascii=False)

        logger.info(f"æ€ç»´é“¾å·²å¯¼å‡ºåˆ°: {file_path}")


class MinimaxClient:
    """Minimax APIå®¢æˆ·ç«¯"""

    def __init__(self, api_key: str, base_url: str = "https://api.minimaxi.com/v1/text/chatcompletion_v2",
                 model: AIModel = AIModel.MINIMAX_M2):
        """
        åˆå§‹åŒ–Minimaxå®¢æˆ·ç«¯

        Args:
            api_key: APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            model: ä½¿ç”¨çš„AIæ¨¡å‹
        """
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.chain_logger = ChainOfThoughtLogger()

        # é…ç½®HTTPä¼šè¯å’Œé‡è¯•ç­–ç•¥
        self.session = requests.Session()
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

        # è®¾ç½®è¯·æ±‚å¤´
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        logger.info(f"Minimaxå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {model.value}")

    def chat(self, messages: List[Dict[str, str]], temperature: float = 0.7,
             max_tokens: int = 4000) -> AIResponse:
        """
        å‘é€èŠå¤©è¯·æ±‚

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§ä»¤ç‰Œæ•°

        Returns:
            AIå“åº”ç»“æœ
        """
        # åªè¾“å‡ºå…³é”®ä¿¡æ¯
        user_msg = next((msg.get("content", "") for msg in messages if msg.get("role") == "user"), "")
        if user_msg:
            logger.info(f"ğŸ’¬ å‘é€è¯·æ±‚ ({self.model.value})...")
        
        self.chain_logger.add_step(
            "APIè¯·æ±‚å‡†å¤‡",
            {"messages": messages, "messages_count": len(messages), "temperature": temperature, "max_tokens": max_tokens},
            {"model": self.model.value},
            "å‡†å¤‡å‘é€è¯·æ±‚åˆ°Minimax API",
            confidence=1.0,
            verbose=False
        )

        request_data = {
            "model": self.model.value,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": True  # å¯ç”¨æµå¼è¾“å‡º
        }

        try:
            # é™é»˜è®°å½•æ­¥éª¤
            self.chain_logger.add_step(
                "å‘é€APIè¯·æ±‚",
                {"url": self.base_url},
                "è¯·æ±‚ä¸­...",
                "å‘Minimax APIå‘é€HTTPè¯·æ±‚",
                confidence=1.0,
                verbose=False
            )

            # æµå¼è¯·æ±‚
            response = self.session.post(
                self.base_url,
                headers=self.headers,
                json=request_data,
                timeout=60,
                stream=True
            )

            response.raise_for_status()
            
            # æµå¼å¤„ç†å“åº”
            content = ""
            usage = {}
            finish_reason = "stop"
            model_name = self.model.value
            
            logger.info("ğŸ¤– AIå“åº”:")
            print("â”€" * 80)
            sys.stdout.flush()
            
            for line in response.iter_lines():
                if not line:
                    continue
                    
                line_text = line.decode('utf-8')
                # å¤„ç†SSEæ ¼å¼: data: {...}
                if line_text.startswith('data: '):
                    data_str = line_text[6:].strip()
                    if data_str == '[DONE]':
                        break
                    
                    try:
                        data = json.loads(data_str)
                        if "choices" in data and len(data["choices"]) > 0:
                            choice = data["choices"][0]
                            delta = choice.get("delta", {})
                            if "content" in delta:
                                chunk = delta["content"]
                                content += chunk
                                # å®æ—¶è¾“å‡ºï¼Œä¸ä½¿ç”¨loggeré¿å…æ—¶é—´æˆ³
                                sys.stdout.write(chunk)
                                sys.stdout.flush()
                            
                            # æ›´æ–°usageå’Œfinish_reason
                            if "usage" in data:
                                usage.update(data["usage"])
                            if "finish_reason" in choice and choice["finish_reason"]:
                                finish_reason = choice["finish_reason"]
                            if "model" in data:
                                model_name = data["model"]
                    except json.JSONDecodeError as e:
                        # å¿½ç•¥è§£æé”™è¯¯ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€è¡Œ
                        continue
            
            print()  # æ¢è¡Œ
            print("â”€" * 80)
            sys.stdout.flush()
            
            self.chain_logger.add_step(
                "å¤„ç†APIå“åº”",
                {"status_code": response.status_code},
                {"content_length": len(content)},
                "è§£æAPIæµå¼å“åº”æ•°æ®",
                confidence=1.0,
                verbose=False
            )

            ai_response = AIResponse(
                content=content,
                model=model_name,
                usage=usage,
                finish_reason=finish_reason,
                chain_of_thought=self._extract_chain_of_thought(content)
            )

            self.chain_logger.add_step(
                "ç”Ÿæˆæœ€ç»ˆå“åº”",
                {},
                ai_response,
                "æ„å»ºAIå“åº”å¯¹è±¡å¹¶æå–æ€ç»´é“¾",
                confidence=0.9,
                verbose=False
            )

            return ai_response

        except requests.exceptions.RequestException as e:
            error_msg = f"APIè¯·æ±‚å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            self.chain_logger.add_step(
                "APIè¯·æ±‚é”™è¯¯",
                {"error": str(e)},
                None,
                "å¤„ç†APIè¯·æ±‚å¼‚å¸¸",
                confidence=0.0
            )
            raise
        except Exception as e:
            error_msg = f"å“åº”å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            self.chain_logger.add_step(
                "å“åº”å¤„ç†é”™è¯¯",
                {"error": str(e)},
                None,
                "å¤„ç†å“åº”æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸",
                confidence=0.0
            )
            raise

    def _extract_chain_of_thought(self, content: str) -> Optional[str]:
        """ä»å“åº”å†…å®¹ä¸­æå–æ€ç»´é“¾"""
        # å°è¯•ä»å“åº”ä¸­æå–æ€ç»´é“¾æ ‡è®°çš„å†…å®¹
        lines = content.split('\n')
        chain_parts = []

        in_thought_chain = False
        for line in lines:
            line = line.strip()
            if "æ€ç»´é“¾" in line or "æ¨ç†è¿‡ç¨‹" in line or "chain of thought" in line.lower():
                in_thought_chain = True
                continue
            elif line.startswith("---") or "ç»“è®º" in line:
                if in_thought_chain:
                    break

            if in_thought_chain and line:
                chain_parts.append(line)

        return '\n'.join(chain_parts) if chain_parts else None

    def analyze_vulnerability(self, vulnerability_data: Dict[str, Any]) -> AIResponse:
        """
        åˆ†ææ¼æ´å¹¶ç”Ÿæˆä¿®å¤å»ºè®®

        Args:
            vulnerability_data: æ¼æ´ä¿¡æ¯

        Returns:
            AIåˆ†æç»“æœ
        """
        self.chain_logger.add_step(
            "æ¼æ´åˆ†æå¼€å§‹",
            vulnerability_data,
            "åˆ†æä¸­...",
            "å¼€å§‹ä½¿ç”¨AIåˆ†ææ¼æ´è¯¦æƒ…",
            confidence=1.0,
            verbose=False
        )

        # æ„å»ºåˆ†ææç¤º
        prompt = self._build_vulnerability_analysis_prompt(vulnerability_data)

        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯GitHub Actionå®‰å…¨ä¸“å®¶ï¼Œä¸“æ³¨åˆ†æå’Œä¿®å¤å·¥ä½œæµå®‰å…¨æ¼æ´ã€‚è¾“å‡ºç®€æ´ã€ä¸“ä¸šã€å¯æ‰§è¡Œã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        response = self.chat(messages, temperature=0.3, max_tokens=2000)

        self.chain_logger.add_step(
            "æ¼æ´åˆ†æå®Œæˆ",
            vulnerability_data,
            response.content,
            f"å®Œæˆæ¼æ´åˆ†æï¼Œç”Ÿæˆäº†{len(response.content)}å­—ç¬¦çš„ä¿®å¤å»ºè®®",
            confidence=0.9,
            verbose=False
        )

        return response

    def generate_fix_code(self, workflow_content: str, vulnerability_info: Dict[str, Any]) -> AIResponse:
        """
        ç”Ÿæˆå…·ä½“çš„ä¿®å¤ä»£ç 

        Args:
            workflow_content: å·¥ä½œæµå†…å®¹
            vulnerability_info: æ¼æ´ä¿¡æ¯

        Returns:
            ä¿®å¤ä»£ç å»ºè®®
        """
        self.chain_logger.add_step(
            "ä¿®å¤ä»£ç ç”Ÿæˆå¼€å§‹",
            {"workflow_length": len(workflow_content), "vulnerability": vulnerability_info},
            "ç”Ÿæˆä¸­...",
            "å¼€å§‹ä½¿ç”¨AIç”Ÿæˆå…·ä½“çš„ä¿®å¤ä»£ç ",
            confidence=1.0,
            verbose=False
        )

        # æ„å»ºä»£ç ä¿®å¤æç¤º
        prompt = self._build_fix_code_prompt(workflow_content, vulnerability_info)

        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯GitHub Actionå®‰å…¨ä¿®å¤ä¸“å®¶ã€‚è¾“å‡ºå®Œæ•´ã€å®‰å…¨ã€å¯ç”¨çš„YAMLä»£ç ï¼Œä»…ä¿®å¤æŒ‡å®šæ¼æ´ï¼Œä¿æŒåŸæœ‰åŠŸèƒ½ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        response = self.chat(messages, temperature=0.2, max_tokens=3000)

        self.chain_logger.add_step(
            "ä¿®å¤ä»£ç ç”Ÿæˆå®Œæˆ",
            {"workflow_length": len(workflow_content)},
            response.content,
            f"ç”Ÿæˆäº†{len(response.content)}å­—ç¬¦çš„ä¿®å¤ä»£ç ",
            confidence=0.9,
            verbose=False
        )

        return response

    def _build_vulnerability_analysis_prompt(self, vulnerability_data: Dict[str, Any]) -> str:
        """æ„å»ºæ¼æ´åˆ†ææç¤º"""
        return f"""åˆ†æGitHub Actionå®‰å…¨æ¼æ´å¹¶æä¾›ä¿®å¤æ–¹æ¡ˆã€‚

æ¼æ´ä¿¡æ¯ï¼š
- è§„åˆ™ID: {vulnerability_data.get('rule_id', 'unknown')}
- ä¸¥é‡æ€§: {vulnerability_data.get('severity', 'unknown')}
- æè¿°: {vulnerability_data.get('message', 'unknown')}
- ä½ç½®: {vulnerability_data.get('workflow', 'unknown')}/{vulnerability_data.get('job', 'unknown')}/{vulnerability_data.get('step', 'unknown')}

è¾“å‡ºè¦æ±‚ï¼š
1. ç®€è¦è¯´æ˜å®‰å…¨é£é™©å’Œæ”»å‡»å‘é‡
2. æä¾›å¯è¡Œçš„ä¿®å¤æ–¹æ¡ˆ
3. è¯„ä¼°ä¿®å¤ä¼˜å…ˆçº§ï¼ˆP0/P1/P2ï¼‰
4. è¯´æ˜ä¿®å¤ç†ç”±

è¯·ç”¨ç®€æ´ã€ç»“æ„åŒ–çš„æ–¹å¼è¾“å‡ºã€‚"""

    def _build_fix_code_prompt(self, workflow_content: str, vulnerability_info: Dict[str, Any]) -> str:
        """æ„å»ºä»£ç ä¿®å¤æç¤º"""
        return f"""ä¿®å¤ä»¥ä¸‹GitHub Actionå·¥ä½œæµçš„å®‰å…¨æ¼æ´ï¼š

å½“å‰å·¥ä½œæµï¼š
```yaml
{workflow_content}
```

æ¼æ´ä¿¡æ¯ï¼š
- ç±»å‹: {vulnerability_info.get('rule_id', 'unknown')}
- æè¿°: {vulnerability_info.get('message', 'unknown')}
- ä½ç½®: {vulnerability_info.get('workflow', 'unknown')}/{vulnerability_info.get('job', 'unknown')}/{vulnerability_info.get('step', 'unknown')}

è¦æ±‚ï¼š
1. ä»…ä¿®å¤æŒ‡å®šæ¼æ´ï¼Œä¸æ”¹åŠ¨å…¶ä»–ä»£ç 
2. ä¿æŒåŸæœ‰åŠŸèƒ½ä¸å˜
3. ä½¿ç”¨å®‰å…¨çš„ç¼–ç å®è·µï¼ˆè¾“å…¥éªŒè¯ã€å‚æ•°åŒ–æŸ¥è¯¢ç­‰ï¼‰
4. è¾“å‡ºå®Œæ•´ä¿®å¤åçš„YAMLä»£ç 
5. ç”¨æ³¨é‡Šè¯´æ˜ä¿®å¤ç†ç”±

ç›´æ¥è¾“å‡ºä¿®å¤åçš„YAMLä»£ç ï¼ˆåŒ…å«```yamlä»£ç å—ï¼‰ã€‚"""

    def get_chain_of_thought(self) -> ChainOfThoughtLogger:
        """è·å–æ€ç»´é“¾è®°å½•å™¨"""
        return self.chain_logger

    def reset_chain_of_thought(self) -> None:
        """é‡ç½®æ€ç»´é“¾è®°å½•"""
        self.chain_logger = ChainOfThoughtLogger()
